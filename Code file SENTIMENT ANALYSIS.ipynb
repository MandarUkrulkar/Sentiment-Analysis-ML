{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a79fbe8",
   "metadata": {
    "id": "0a79fbe8"
   },
   "source": [
    "# SENTIMENT ANALYSIS OF RESTAURANT REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec86e92",
   "metadata": {
    "id": "7ec86e92"
   },
   "source": [
    "# Creation of the initial dataset (30/11/2022 – 05/12/2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc367b",
   "metadata": {
    "id": "53bc367b"
   },
   "source": [
    "Lest first create a dataframe named 'df' from our provided tsv file for Restaurant reviews. We will use PANDAS for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906dd2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1675927413741,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "906dd2ab",
    "outputId": "c818457b-0067-48cb-bd38-05ad1d0ad556"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('Restaurant_Reviews.tsv',delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca2e1e",
   "metadata": {
    "id": "7cca2e1e"
   },
   "source": [
    "Now we will process our data in dataframe , as we can see that review sentences have words including \n",
    "capitals, punctuations, spelling mistakes and non required words,\n",
    "which needs to be removed before feeding data to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d1e27a",
   "metadata": {
    "id": "31d1e27a"
   },
   "outputs": [],
   "source": [
    "import re   # Regular Expression package\n",
    "\n",
    "# Cleaning the reviews\n",
    "cleaned_reviews = []\n",
    "for i in df['Review']:\n",
    "    \n",
    "    review = re.sub(pattern='[^a-zA-Z]',repl=' ', string=i)# Cleaning special character from the reviews\n",
    "    \n",
    "    review = review.lower() # Converting the entire review into lower case\n",
    "\n",
    "   \n",
    "    cleaned_reviews.append(review)   # Creating clean review column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf61858",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1675927422368,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "6bf61858",
    "outputId": "ca536810-a832-4073-a691-e311987c74a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Cleaned reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow    loved this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>i think food should have flavor and texture an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>appetite instantly gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>overall i was not impressed and would not go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the whole experience was underwhelming  and i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>then  as if i hadn t wasted enough of my life ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked  \\\n",
       "0                             Wow... Loved this place.      1   \n",
       "1                                   Crust is not good.      0   \n",
       "2            Not tasty and the texture was just nasty.      0   \n",
       "3    Stopped by during the late May bank holiday of...      1   \n",
       "4    The selection on the menu was great and so wer...      1   \n",
       "..                                                 ...    ...   \n",
       "995  I think food should have flavor and texture an...      0   \n",
       "996                           Appetite instantly gone.      0   \n",
       "997  Overall I was not impressed and would not go b...      0   \n",
       "998  The whole experience was underwhelming, and I ...      0   \n",
       "999  Then, as if I hadn't wasted enough of my life ...      0   \n",
       "\n",
       "                                       Cleaned reviews  \n",
       "0                             wow    loved this place   \n",
       "1                                   crust is not good   \n",
       "2            not tasty and the texture was just nasty   \n",
       "3    stopped by during the late may bank holiday of...  \n",
       "4    the selection on the menu was great and so wer...  \n",
       "..                                                 ...  \n",
       "995  i think food should have flavor and texture an...  \n",
       "996                           appetite instantly gone   \n",
       "997  overall i was not impressed and would not go b...  \n",
       "998  the whole experience was underwhelming  and i ...  \n",
       "999  then  as if i hadn t wasted enough of my life ...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned reviews']=cleaned_reviews  #adding column to the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0d8322",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675927427773,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "cf0d8322",
    "outputId": "24cc74b4-8dff-4e8b-b149-002338e94bbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "      <th>Cleaned reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wow    loved this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>now i am getting angry and i want my damn pho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>honeslty it didn t taste that fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the potatoes were like rubber and you could te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>the fries were great too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>a great touch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Liked                                    Cleaned reviews\n",
       "0      1                           wow    loved this place \n",
       "1      0                                 crust is not good \n",
       "2      0          not tasty and the texture was just nasty \n",
       "3      1  stopped by during the late may bank holiday of...\n",
       "4      1  the selection on the menu was great and so wer...\n",
       "5      0     now i am getting angry and i want my damn pho \n",
       "6      0              honeslty it didn t taste that fresh  \n",
       "7      0  the potatoes were like rubber and you could te...\n",
       "8      1                          the fries were great too \n",
       "9      1                                     a great touch "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unwanted column\n",
    "del df['Review']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed6f24",
   "metadata": {
    "id": "75ed6f24"
   },
   "source": [
    "# Data Extraction through web (06/12/2022) - (13/12/2022)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c134a1d",
   "metadata": {
    "id": "9c134a1d"
   },
   "source": [
    "# #WEBSCRAPING\n",
    "Now we will extract data from web by webscraping, here we need reviews about restaurant.\n",
    "We will need two libraries as 'requests' and 'beautiful soup'.\n",
    "Website: MAGICPIN.COM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994ced2",
   "metadata": {
    "id": "a994ced2"
   },
   "source": [
    "First we will scrape review for multiple restaurants having only one page for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e9d521",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38754,
     "status": "ok",
     "timestamp": 1675927469627,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "b0e9d521",
    "outputId": "a1253aec-5d19-49a7-a1d9-94bdc4370e57"
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='magicpin.in', port=443): Max retries exceeded with url: /Mumbai/Mumbai-Central/Restaurant/Food-Box/store/2ac94/reviews/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023A8D607760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x0000023A8D607760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='magicpin.in', port=443): Max retries exceeded with url: /Mumbai/Mumbai-Central/Restaurant/Food-Box/store/2ac94/reviews/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023A8D607760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4876\\1293753932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0msite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'section'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'merchant-brick merchant-ratings merchant-recent-ratings'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    563\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='magicpin.in', port=443): Max retries exceeded with url: /Mumbai/Mumbai-Central/Restaurant/Food-Box/store/2ac94/reviews/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023A8D607760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "#  now scraping from multiple urls\n",
    "    \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=['https://magicpin.in/Mumbai/Mumbai-Central/Restaurant/Food-Box/store/2ac94/reviews/',\n",
    "     'https://magicpin.in/Mumbai/Town-Hall/Restaurant/Aromas-Cafe-and-Bistro/store/57b3b1/reviews/',\n",
    "    'https://magicpin.in/Mumbai/Bhuleshwar/Restaurant/Jilani-Fast-Food-Corner/store/35c2b9/reviews/',\n",
    "    'https://magicpin.in/Mumbai/Fort/Restaurant/Lunchbox---Meals-And-Thalis/store/57bb52/reviews/',\n",
    "    'https://magicpin.in/Mumbai/Lokhandwala/Restaurant/Ubq-By-Barbeque-Nation/store/13074a3/reviews/',\n",
    "     'https://magicpin.in/Mumbai/Goregaon-West/Restaurant/Green-Leaf---Only-Veg/store/5cc111/reviews/',\n",
    "     'https://magicpin.in/Mumbai/Poonam-Sagar-Complex/Restaurant/Celebration-Point/store/5970cc/reviews/',\n",
    "     'https://magicpin.in/Mumbai/Kandivali-East/Restaurant/Kusum-Rolls/store/399275/reviews/'\n",
    "    \n",
    "    ]\n",
    "newlist=[]  # temporary creating list for storing scraped reviews\n",
    "\n",
    "for a in url:\n",
    "    site=requests.get(a)\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    s=soup.find('section', class_='merchant-brick merchant-ratings merchant-recent-ratings')\n",
    "    content = s.find_all('p', class_='review')\n",
    "    for j in content:\n",
    "        newlist.append(j.text)\n",
    "        \n",
    "newlist1=[] # formating and storing data in new list1\n",
    "for i in newlist:\n",
    "    x=i.strip()\n",
    "    y=x.replace('\\n','')\n",
    "    newlist1.append(y)\n",
    "newlist1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c58a4",
   "metadata": {
    "id": "124c58a4"
   },
   "source": [
    "\n",
    "\n",
    "Now, we will scrape reviews from one restaurant having multiple pages for reviews, \n",
    "\n",
    "we will create the code to extract reviews sentence from page and iterate it over all the pages,\n",
    "\n",
    "in this case there are 59 pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233469c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293766,
     "status": "ok",
     "timestamp": 1675927763388,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "6233469c",
    "outputId": "3e3218f3-bd0e-407d-f76b-d1cec4a561bd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets scrape some more from other restaurant/ url with multiple pages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://magicpin.in/Mumbai/Bandra-West/Restaurant/Barbeque-Nation/store/23368/reviews'\n",
    "newlist=[]\n",
    "for i in range(1,60):  #there are 59 pages for reviews.\n",
    "    site=requests.get(url + str('?page=') + str(i))\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    s=soup.find('section', class_='merchant-brick merchant-ratings merchant-recent-ratings')\n",
    "    content = s.find_all('p', class_='review')\n",
    "    for j in content:\n",
    "        newlist.append(j.text)\n",
    "    \n",
    "\n",
    "for i in newlist:\n",
    "    x=i.strip()\n",
    "    y=x.replace('\\n','')\n",
    "    newlist1.append(y)  #adding new scraped reviews to newlist1\n",
    "newlist1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38953142",
   "metadata": {
    "id": "38953142"
   },
   "source": [
    "It is observed that scraped reviews contain duplictae reviews ,\n",
    "\n",
    "which i think should be removed before going further,\n",
    "\n",
    "this will ensure that our model will be trained on unique and various data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0a705",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1675927763389,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "8eb0a705",
    "outputId": "18a830a4-d5a9-4ec4-9492-2a7eba6eff60"
   },
   "outputs": [],
   "source": [
    "#removing duplicate reviews from list\n",
    "\n",
    "newlist1=[*set(newlist1)]\n",
    "newlist1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c0388",
   "metadata": {
    "id": "205c0388"
   },
   "source": [
    "\n",
    "We will be adding the scraped data to our provided dataset ,\n",
    "\n",
    "so we will clean and format the scraped data first\n",
    "\n",
    "similarly as we didi earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d370fa7",
   "metadata": {
    "id": "6d370fa7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re   # Regular Expression package\n",
    "from nltk.corpus import stopwords   # stopwords package\n",
    "from nltk.stem.porter import PorterStemmer   #porter stemmer for stemming words\n",
    "\n",
    "# Cleaning the reviews\n",
    "cleaned_newreviews=[]\n",
    "for i in newlist1:\n",
    "    \n",
    "    newreview = re.sub(pattern='[^a-zA-Z]',repl=' ', string=i)# Cleaning special character from the reviews\n",
    "    \n",
    "    newreview = newreview.lower() # Converting the entire review into lower case\n",
    "   \n",
    "   \n",
    "    cleaned_newreviews.append(newreview)   # Creating clean_newreviews list\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c6718",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1675927764278,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "4a9c6718",
    "outputId": "948461bc-63a3-4d9f-f8b6-f912407cbe82"
   },
   "outputs": [],
   "source": [
    "cleaned_newreviews   # displaying the cleaned list of scraped reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4e604",
   "metadata": {
    "id": "43e4e604"
   },
   "source": [
    "Before adding these scraped reviews to our original dataframe, \n",
    "\n",
    "we need to classify them , lets create a df2 for these reviews to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887ba4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1675927764280,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "1887ba4e",
    "outputId": "e54217dd-ee14-4bc1-fea7-7f317affe098"
   },
   "outputs": [],
   "source": [
    "#creating new dataframe df2 from newliked and cleaned_newreviews lists\n",
    " # creating new liked with values baser upon the review polarity\n",
    "df2=pd.DataFrame({\"Cleaned reviews\":cleaned_newreviews})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9db9e",
   "metadata": {
    "id": "29c9db9e"
   },
   "source": [
    "As we can see that it has 173 new scraped reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774937b",
   "metadata": {
    "id": "2774937b"
   },
   "source": [
    "Now we will classify the scraped reviews by kmeans ,\n",
    "\n",
    "first we will convert words to numerical arrays by using count vetorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5559f91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1675927764281,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "b5559f91",
    "outputId": "60631a1e-4f7a-4fed-f9e9-2451679a7ee5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "Tvect = TfidfVectorizer(stop_words='english')\n",
    "Cvect = CountVectorizer()\n",
    "\n",
    "\n",
    "\n",
    "X = Cvect.fit_transform(cleaned_newreviews)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378253be",
   "metadata": {
    "id": "378253be"
   },
   "outputs": [],
   "source": [
    "# Create \"Liked \" feature colum in dataframe\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, max_iter=10000)\n",
    "df2[\"Liked\"] = kmeans.fit_predict(X)\n",
    "df2[\"Liked\"] = df2[\"Liked\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7461af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675928111057,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "ec7461af",
    "outputId": "e6d7c687-3e42-4b72-e0d3-b17cb0bf8e3c"
   },
   "outputs": [],
   "source": [
    "df2.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eada31e",
   "metadata": {
    "id": "0eada31e"
   },
   "source": [
    "# UPDATING DATAFRAME WITH SCRAPED REVIEWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9b02d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1675928126690,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "e3f9b02d",
    "outputId": "f88f96f6-c0f4-4600-c9b3-1ed3800cc617"
   },
   "outputs": [],
   "source": [
    "df  #  checking orignal clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4431d",
   "metadata": {
    "id": "92a4431d"
   },
   "outputs": [],
   "source": [
    "df3=df.append(df2, ignore_index=True) # adding new cleaned reviews datframe to original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc679a05",
   "metadata": {
    "id": "dc679a05"
   },
   "source": [
    "df3 is our latest dataframe including intial cleaned data as well as new extracted and cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078edabb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1675928139454,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "078edabb",
    "outputId": "613c5656-b12c-4579-a0b5-3fce1ab33fe7"
   },
   "outputs": [],
   "source": [
    "\n",
    "df3.to_csv('updated_reviews_with_scraped.csv', index=False)# lets scae df to csv as scraping takes time.\n",
    "df3 # df3 is our latest dataframeincluding intial cleaned data as well as new extracted and cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a45ec",
   "metadata": {
    "id": "a92a45ec"
   },
   "source": [
    "# Exploratory Data Analysis (14/12/2022 – 19/12/2022) \n",
    "\n",
    "we will do EDA upon our new df3 dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0d77e",
   "metadata": {
    "id": "57d0d77e"
   },
   "source": [
    "We will look at the information about our data,\n",
    "\n",
    "Before loading the dataframe below we have verified whether the classification is done accurately, if not then it is corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebde8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1675928156865,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "ecebde8d",
    "outputId": "b9531569-2c63-4623-a7f7-9f08d3f58f6e"
   },
   "outputs": [],
   "source": [
    "#we have exported our dataframe df3 as csv file lets load it.\n",
    "import pandas as pd\n",
    "df3=pd.read_csv('updated_reviews_with_scraped_edited.csv')\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d28b6e",
   "metadata": {
    "id": "c7d28b6e"
   },
   "source": [
    "Here we observed that some values are missing so removing null values by droping rows containing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011fda0",
   "metadata": {
    "id": "1011fda0"
   },
   "outputs": [],
   "source": [
    "df3=df3.dropna()\n",
    "df3=df3.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2174",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675928163523,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "01fd2174",
    "outputId": "0353410a-c374-43c2-d261-c3e4f52b2d6f"
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2daa4a6",
   "metadata": {
    "id": "f2daa4a6"
   },
   "source": [
    "Sentiment count:\n",
    "Here, we will see number of negative and positive reviews in the given data set, to make sure whether the datset is balanced or not.We will plot a pie diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67905e55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "executionInfo": {
     "elapsed": 1954,
     "status": "ok",
     "timestamp": 1675928186362,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "67905e55",
    "outputId": "99580610-3b97-4bd8-8979-6827216c4b36"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "colors=[\"blue\",'pink']\n",
    "pos=df3[df3['Liked']==1]\n",
    "neg=df3[df3['Liked']==0]\n",
    "ck=[pos['Liked'].count(),neg['Liked'].count()]\n",
    "legpie=plt.pie(ck,labels=[\"Positive\",\"Negative\"],\n",
    "                 autopct ='%1.1f%%', \n",
    "                 shadow = True,\n",
    "                 colors = colors,\n",
    "                 startangle = 45,\n",
    "                 explode=(0, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d859f1",
   "metadata": {
    "id": "12d859f1"
   },
   "source": [
    "# Text visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7dc26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1675928208684,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "97e7dc26",
    "outputId": "daf68f9e-0d44-4fd9-f856-5ebc6e94fea1"
   },
   "outputs": [],
   "source": [
    "df4 = df3[\"Cleaned reviews\"].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()\n",
    "df4.columns = [\"words\", \"counts\"]\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e20b47",
   "metadata": {
    "id": "e3e20b47"
   },
   "outputs": [],
   "source": [
    "df4=df4.sort_values(\"counts\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d61a4",
   "metadata": {
    "id": "180d61a4"
   },
   "source": [
    "Top 25 repeated words with their counts can be seen in bar garph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed4f83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675928239884,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "a4ed4f83",
    "outputId": "3684ec26-05dd-4223-a7b5-4bce89be996e"
   },
   "outputs": [],
   "source": [
    "df4[df4[\"counts\"]> 50].plot.bar(x=\"words\", y=\"counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80945a81",
   "metadata": {
    "id": "80945a81"
   },
   "source": [
    "\n",
    "#  Feature Engineering (20/12/2022 – 28/12/2022) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587965dd",
   "metadata": {
    "id": "587965dd"
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b59bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1675928248007,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "174b59bd",
    "outputId": "b4c816dc-5b99-465f-8a34-64de9bf6acff"
   },
   "outputs": [],
   "source": [
    "#The goal of feature engineering is simply to make your data better suited to the problem at hand.\n",
    "\n",
    "#lets view our latest dataframe df3 which contain intial as well as scraped data, cleaned and combined.\n",
    "import pandas as pd\n",
    "df3=pd.read_csv('updated_reviews_with_scraped_edited.csv')\n",
    "df3=df3.dropna()\n",
    "df3=df3.reset_index(drop=True) \n",
    "df3.info()\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da633f",
   "metadata": {
    "id": "24da633f"
   },
   "source": [
    "-Our dataframe contains only two features one is 'Liked' which contain polarity of review and other is 'Cleaned reviews' containing cleaned text .\n",
    "\n",
    "-'Liked' column is target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd03de",
   "metadata": {
    "id": "62cd03de"
   },
   "source": [
    "Here we will be creating new feature from our exixsting 'Cleaned reviews' feature's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d386874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1675928254212,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "4d386874",
    "outputId": "4aaeeb65-a098-4bca-f441-aa5e04074e12"
   },
   "outputs": [],
   "source": [
    "#Using  vectorizer which convets words into vectors.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "Tvect = TfidfVectorizer(stop_words='english')\n",
    "Cvect = CountVectorizer()\n",
    "\n",
    "X= Cvect.fit_transform(df3['Cleaned reviews']).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a5460",
   "metadata": {
    "id": "0b2a5460"
   },
   "source": [
    "Now we will view our new created features by converting the array into dataframe\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e7a59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675928282289,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "8d4e7a59",
    "outputId": "723569fc-bf5a-4fb3-966b-fe0720a2e619"
   },
   "outputs": [],
   "source": [
    "Xlist=list(X)  #converting to list\n",
    "df3['word_vector']=Xlist # adding under new feature - 'Word vector'\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91f719",
   "metadata": {
    "id": "5e91f719"
   },
   "source": [
    "Above we have created new feature name 'word vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be385e5b",
   "metadata": {
    "id": "be385e5b"
   },
   "source": [
    "#  PREDICTIVE MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5a42848",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1477,
     "status": "ok",
     "timestamp": 1676094227359,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "a5a42848",
    "outputId": "5b7827f7-851b-42c0-a597-5f2f9b4aafe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1173 entries, 0 to 1172\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Liked            1173 non-null   int64 \n",
      " 1   Cleaned reviews  1173 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df3=pd.read_csv('updated_reviews_with_scraped_edited.csv')\n",
    "df3=df3.dropna()\n",
    "df3=df3.reset_index(drop=True) \n",
    "df3.info()\n",
    "df3\n",
    "\n",
    "#creating target variable\n",
    "X=df3['Cleaned reviews']\n",
    "y=df3.Liked\n",
    "\n",
    "\n",
    "#Using  vectorizer which convets words into vectors.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "Tvect = TfidfVectorizer(stop_words='english')\n",
    "Cvect = CountVectorizer()\n",
    "\n",
    "X= Cvect.fit_transform(df3['Cleaned reviews']).toarray()\n",
    "\n",
    "\n",
    "\n",
    "#Creating a train test split from data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.1,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e985e",
   "metadata": {
    "id": "eb9e985e"
   },
   "source": [
    "# Lets create models using various classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56915bef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1676094242263,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "56915bef",
    "outputId": "bfcff430-a330-4d9b-9bfb-cfb2216a1323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 88.14%\n",
      "Precision score is: 0.92\n",
      "Recall score is: 0.82\n"
     ]
    }
   ],
   "source": [
    "#1- Using Logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression(random_state=100).fit(X_train,y_train)\n",
    "ypred=model1.predict(X_test)\n",
    "print('Logistic regression model evaluation')\n",
    "\n",
    "# Accuracy, Precision and Recall \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,ypred)\n",
    "score2 = precision_score(y_test,ypred)\n",
    "score3= recall_score(y_test,ypred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf59c678",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2235,
     "status": "ok",
     "timestamp": 1676094260959,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "bf59c678",
    "outputId": "e3af29f6-4d3a-4412-b294-0b3ac311c150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 83.05%\n",
      "Precision score is: 0.88\n",
      "Recall score is: 0.75\n"
     ]
    }
   ],
   "source": [
    "#2-Using Support Vector Classifier or SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model2 = SVC(random_state=50)\n",
    "model2.fit(X_train, y_train)\n",
    "ypred = model2.predict(X_test)\n",
    "\n",
    "print('SVC model evaluation')\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,ypred)\n",
    "score2 = precision_score(y_test,ypred)\n",
    "score3= recall_score(y_test,ypred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0925f52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1676094266130,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "a0925f52",
    "outputId": "2a1bbb71-d722-4ad3-a4d6-680a165bc327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 82.2%\n",
      "Precision score is: 0.82\n",
      "Recall score is: 0.8\n",
      "GaussianNB model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 71.19%\n",
      "Precision score is: 0.65\n",
      "Recall score is: 0.86\n",
      "MultinomialNB model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 87.29%\n",
      "Precision score is: 0.92\n",
      "Recall score is: 0.8\n"
     ]
    }
   ],
   "source": [
    "#3-Using Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB,GaussianNB,MultinomialNB\n",
    "\n",
    "NB=[BernoulliNB,GaussianNB,MultinomialNB]\n",
    "for i in NB:\n",
    "    model3=i().fit(X_train,y_train)\n",
    "    ypred=model3.predict(X_test)\n",
    "    print(i.__name__,'model evaluation')\n",
    "    # Accuracy, Precision and Recall\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    score1 = accuracy_score(y_test,ypred)\n",
    "    score2 = precision_score(y_test,ypred)\n",
    "    score3= recall_score(y_test,ypred)\n",
    "    print(\"---- Scores ----\")\n",
    "    print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "    print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "    print(\"Recall score is: {}\".format(round(score3,2)))\n",
    "\n",
    "    \n",
    "model3a=BernoulliNB().fit(X_train,y_train)\n",
    "    \n",
    "model3b=GaussianNB().fit(X_train,y_train)\n",
    "    \n",
    "model3c=MultinomialNB().fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "G1PlhBXbCl4h",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676095169771,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "G1PlhBXbCl4h"
   },
   "outputs": [],
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Un7moECaAQ33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30139,
     "status": "ok",
     "timestamp": 1676095005551,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "Un7moECaAQ33",
    "outputId": "76acf5da-c476-4f51-e972-6c0e1772c35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.7542372881355932\n",
      "20 0.7796610169491526\n",
      "30 0.788135593220339\n",
      "40 0.8305084745762712\n",
      "50 0.8559322033898306\n",
      "60 0.8559322033898306\n",
      "70 0.8898305084745762\n",
      "80 0.8305084745762712\n",
      "90 0.8813559322033898\n",
      "\n",
      " 70 0.8898305084745762\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning for Random FOrest\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_n = 0\n",
    "best_acc = 0\n",
    "for n in range(10,100,10):\n",
    "    model4b = RandomForestClassifier(criterion='entropy', n_estimators=n,max_depth=n)\n",
    "    model4b.fit(X_train,y_train)\n",
    "    y_pred=model4b.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_n = n\n",
    "        best_acc = acc\n",
    "    print(n, acc)\n",
    "print('\\n', best_n, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51b0b444",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1676095041346,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "51b0b444",
    "outputId": "4b5f0b6e-18c6-4b99-e501-466e786355f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 87.29%\n",
      "Precision score is: 0.86\n",
      "Recall score is: 0.88\n"
     ]
    }
   ],
   "source": [
    "#4-Using Random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model4=RandomForestClassifier(n_estimators = 70, criterion = 'entropy', max_depth=70)\n",
    "model4.fit(X_train,y_train)\n",
    "ypred=model4.predict(X_test)\n",
    "print('RandomForest model evaluation')\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,ypred)\n",
    "score2 = precision_score(y_test,ypred)\n",
    "score3= recall_score(y_test,ypred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a7271f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14215,
     "status": "ok",
     "timestamp": 1675954483984,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "4a7271f1",
    "outputId": "5fdb412c-5b9f-4e26-e45a-ea334e6757fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBclassifier model evaluation\n",
      "---- Scores ----\n",
      "Accuracy score is: 85.59%\n",
      "Precision score is: 0.85\n",
      "Recall score is: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Using XGB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "model5 = XGBClassifier(max_depth=10, n_estimators=100).fit(X_train,y_train)\n",
    "ypred=model5.predict(X_test)\n",
    "print('XGBclassifier model evaluation')\n",
    "\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,ypred)\n",
    "score2 = precision_score(y_test,ypred)\n",
    "score3= recall_score(y_test,ypred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e08c5",
   "metadata": {
    "id": "cd6e08c5"
   },
   "source": [
    "# Review prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hrUnbmFuqgYj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1676095070572,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "hrUnbmFuqgYj",
    "outputId": "e7983a55-5b4b-4c6d-ebaf-33b2e5767a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1173 entries, 0 to 1172\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Liked            1173 non-null   int64 \n",
      " 1   Cleaned reviews  1173 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df3=pd.read_csv('updated_reviews_with_scraped_edited.csv')\n",
    "df3=df3.dropna()\n",
    "df3=df3.reset_index(drop=True) \n",
    "df3.info()\n",
    "df3\n",
    "\n",
    "#creating target variable\n",
    "X=df3['Cleaned reviews']\n",
    "y=df3.Liked\n",
    "\n",
    "\n",
    "#Creating a train test split from data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.1,random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "975b124e",
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1676095082119,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "975b124e"
   },
   "outputs": [],
   "source": [
    "#lets predict sample review using our various models\n",
    "\n",
    "import re   # Regular Expression package\n",
    "\n",
    "#lets define a function for prediction\n",
    "def predict_sentiment(sample_review):\n",
    "    sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ', string = sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    temp = Cvect.transform([sample_review]).toarray()\n",
    "    return model1.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "D2qH-2pprLBY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1676095089266,
     "user": {
      "displayName": "Mandar Ukrulkar",
      "userId": "03686931402341720923"
     },
     "user_tz": -330
    },
    "id": "D2qH-2pprLBY",
    "outputId": "6a99e248-ba92-467f-debd-c37f00d5b22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- insults  profound deuchebaggery  and had to go outside for a smoke break while serving just to solidify it  : This is a NEGATIVE review!\n",
      "- how can you call yourself a steakhouse if you can t properly cook a steak  i don t understand  : This is a NEGATIVE review!\n",
      "- i don t think i ll be running back to carly s anytime soon for food  : This is a NEGATIVE review!\n",
      "- anyway  this fs restaurant has a wonderful breakfast lunch  : This is a POSITIVE review.\n",
      "- i had to wait over    minutes to get my drink and longer to get   arepas  : This is a NEGATIVE review!\n",
      "- chuck : This is a NEGATIVE review!\n",
      "- i don t recommend unless your car breaks down in front of it and you are starving  : This is a NEGATIVE review!\n",
      "- the black eyed peas and sweet potatoes    unreal  : This is a POSITIVE review.\n",
      "- i could care less    the interior is just beautiful  : This is a POSITIVE review.\n",
      "- i vomited in the bathroom mid lunch  : This is a NEGATIVE review!\n",
      "- great pork sandwich  : This is a POSITIVE review.\n",
      "- i immediately said i wanted to talk to the manager but i did not want to talk to the guy who was doing shots of fireball behind the bar  : This is a NEGATIVE review!\n",
      "- the first time i ever came here i had an amazing experience  i still tell people how awesome the duck was  : This is a POSITIVE review.\n",
      "- the jamaican mojitos are delicious  : This is a POSITIVE review.\n",
      "- you won t be disappointed  : This is a NEGATIVE review!\n",
      "-  it wasn t busy either  also  the building was freezing cold  : This is a NEGATIVE review!\n",
      "- the waitress was friendly and happy to accomodate for vegan veggie options  : This is a POSITIVE review.\n",
      "- the tables outside are also dirty a lot of the time and the workers are not always friendly and helpful with the menu  : This is a NEGATIVE review!\n",
      "- it was way over fried  : This is a NEGATIVE review!\n",
      "- order delivered after   hour   mins    outlet not available on physical location and they didn t even change the location  also  the delivery guy called the outlet multiple times but they didn t answer : This is a NEGATIVE review!\n",
      "- loved the quality  delivery  packaging  and product range at this place : This is a POSITIVE review.\n",
      "- all in all  ha long bay was a bit of a flop  : This is a NEGATIVE review!\n",
      "- thoroughly disappointed  : This is a NEGATIVE review!\n",
      "- great brunch spot  : This is a POSITIVE review.\n",
      "- great food for the price  which is very high quality and house made  : This is a POSITIVE review.\n",
      "- and the beans and rice were mediocre at best  : This is a NEGATIVE review!\n",
      "-   they never brought a salad we asked for  : This is a NEGATIVE review!\n",
      "- loved the food  service  music and drinks at this place : This is a POSITIVE review.\n",
      "- so we went to tigerlilly and had a fantastic afternoon  : This is a POSITIVE review.\n",
      "- hard to judge whether these sides were good because we were grossed out by the melted styrofoam and didn t want to eat it for fear of getting sick  : This is a NEGATIVE review!\n",
      "- the food is not tasty at all  not to say its  real traditional hunan style   : This is a NEGATIVE review!\n",
      "- last night was my second time dining here and i was so happy i decided to go back  : This is a POSITIVE review.\n",
      "- food was great and so was the serivce  : This is a POSITIVE review.\n",
      "- it wasn t busy at all and now we know why  : This is a NEGATIVE review!\n",
      "- food was salty : This is a NEGATIVE review!\n",
      "- no allergy warnings on the menu  and the waitress had absolutely no clue as to which meals did or did not contain peanuts  : This is a NEGATIVE review!\n",
      "- all in all  i can assure you i ll be back  : This is a POSITIVE review.\n",
      "- good : This is a POSITIVE review.\n",
      "- loved the quality  service  safety precautions  and promotions at this place : This is a POSITIVE review.\n",
      "- i did not expect this to be so good  : This is a NEGATIVE review!\n",
      "- loved the food  service  ambience and crowd at this place : This is a POSITIVE review.\n",
      "- the food was very good and i enjoyed every mouthful  an enjoyable relaxed venue for couples small family groups etc  : This is a POSITIVE review.\n",
      "- the food  amazing  : This is a POSITIVE review.\n",
      "- the only downside is the service  : This is a POSITIVE review.\n",
      "- no one at the table thought the food was above average or worth the wait that we had for it  : This is a NEGATIVE review!\n",
      "- go to place for gyros  : This is a NEGATIVE review!\n",
      "- the deal included   tastings and   drinks  and jeff went above and beyond what we expected  : This is a POSITIVE review.\n",
      "- the owners are super friendly and the staff is courteous  : This is a POSITIVE review.\n",
      "- maybe if they weren t cold they would have been somewhat edible  : This is a NEGATIVE review!\n",
      "- what i really like there is the crepe station  : This is a POSITIVE review.\n",
      "- worst service to boot  but that is the least of their worries  : This is a NEGATIVE review!\n",
      "- didn t like the ambience and taste at this place : This is a NEGATIVE review!\n",
      "- please stay away from the shrimp stir fried noodles  : This is a NEGATIVE review!\n",
      "- the selection on the menu was great and so were the prices  : This is a POSITIVE review.\n",
      "- my sashimi was poor quality being soggy and tasteless  : This is a NEGATIVE review!\n",
      "- they have horrible attitudes towards customers  and talk down to each one when customers don t enjoy their food  : This is a NEGATIVE review!\n",
      "- i gave it   stars then  and i m giving it   stars now  : This is a POSITIVE review.\n",
      "- the lighting is just dark enough to set the mood  : This is a POSITIVE review.\n",
      "- i checked out this place a couple years ago and was not impressed  : This is a NEGATIVE review!\n",
      "- there is nothing privileged about working eating there  : This is a NEGATIVE review!\n",
      "- service is very slow : This is a NEGATIVE review!\n",
      "- when i m on this side of town  this will definitely be a spot i ll hit up again  : This is a POSITIVE review.\n",
      "- first time there and might just be the last  : This is a NEGATIVE review!\n",
      "- just spicy enough   perfect actually  : This is a POSITIVE review.\n",
      "- i do love sushi  but i found kabuki to be over priced  over hip and under services  : This is a NEGATIVE review!\n",
      "- the han nan chicken was also very tasty  : This is a POSITIVE review.\n",
      "- she was quite disappointed although some blame needs to be placed at her door  : This is a NEGATIVE review!\n",
      "- this place is pretty good  nice little vibe in the restaurant  : This is a POSITIVE review.\n",
      "- the burger had absolutely no flavor   the meat itself was totally bland  the burger was overcooked and there was no charcoal flavor  : This is a NEGATIVE review!\n",
      "- the flair bartenders are absolutely amazing  : This is a POSITIVE review.\n",
      "- the food was excellent and service was very good  : This is a POSITIVE review.\n",
      "- i took back my money and got outta there  : This is a NEGATIVE review!\n",
      "- also  i feel like the chips are bought  not made in house  : This is a NEGATIVE review!\n",
      "- awesome service and food  : This is a POSITIVE review.\n",
      "- loved the quality of service  ambience  safety precautions  and price  promotions    discounts at this place : This is a POSITIVE review.\n",
      "- didn t like the missing item s  at this place : This is a NEGATIVE review!\n",
      "- also  the fries are without a doubt the worst fries i ve ever had  : This is a NEGATIVE review!\n",
      "- all good : This is a POSITIVE review.\n",
      "- con  spotty service  : This is a NEGATIVE review!\n",
      "- you can watch them preparing the delicious food   : This is a POSITIVE review.\n",
      "- interesting decor  : This is a POSITIVE review.\n",
      "- i got food poisoning here at the buffet  : This is a NEGATIVE review!\n",
      "- the pizza selections are good  : This is a POSITIVE review.\n",
      "- avoid at all cost  : This is a NEGATIVE review!\n",
      "- the food is about on par with denny s  which is to say  not good at all  : This is a NEGATIVE review!\n",
      "- pathetic  : This is a NEGATIVE review!\n",
      "- loved the music  ambience and service at this place : This is a POSITIVE review.\n",
      "- damn good steak  : This is a POSITIVE review.\n",
      "- plus  it s only   bucks  : This is a POSITIVE review.\n",
      "- taste was horrible  and food was too oily  : This is a NEGATIVE review!\n",
      "- the chips and salsa were really good  the salsa was very fresh  : This is a POSITIVE review.\n",
      "- what a mistake that was  : This is a NEGATIVE review!\n",
      "- phenomenal food  service and ambiance  : This is a POSITIVE review.\n",
      "- nargile   i think you are great  : This is a POSITIVE review.\n",
      "- it was attached to a gas station  and that is rarely a good sign  : This is a NEGATIVE review!\n",
      "- do yourself a favor and stay away from this dish  : This is a NEGATIVE review!\n",
      "- the waitress and manager are so friendly  : This is a POSITIVE review.\n",
      "- so don t go there if you are looking for good food    : This is a NEGATIVE review!\n",
      "- fantastic food  : This is a POSITIVE review.\n",
      "- this is a good joint  : This is a POSITIVE review.\n",
      "- they really want to make your experience a good one  : This is a POSITIVE review.\n",
      "- some highlights   great quality nigiri here  : This is a POSITIVE review.\n",
      "- loved the food  service  ambience and music at this place : This is a POSITIVE review.\n",
      "- worst martini ever  : This is a NEGATIVE review!\n",
      "- i hate those things as much as cheap quality black olives  : This is a NEGATIVE review!\n",
      "- the plantains were the worst i ve ever tasted  : This is a NEGATIVE review!\n",
      "- good beer   drink selection and good food selection  : This is a POSITIVE review.\n",
      "- pretty good beer selection too  : This is a POSITIVE review.\n",
      "- food was good  service was good  prices were good  : This is a POSITIVE review.\n",
      "- very friendly staff  : This is a POSITIVE review.\n",
      "- not worth at all waste of money : This is a NEGATIVE review!\n",
      "- the folks at otto always make us feel so welcome and special  : This is a POSITIVE review.\n",
      "- i had a pretty satifying experience  : This is a POSITIVE review.\n",
      "- their rotating beers on tap is also a highlight of this place  : This is a POSITIVE review.\n",
      "- at first glance it is a lovely bakery cafe   nice ambiance  clean  friendly staff  : This is a POSITIVE review.\n",
      "- we are so glad we found this place  : This is a POSITIVE review.\n",
      "- my husband said she was very rude    did not even apologize for the bad food or anything  : This is a NEGATIVE review!\n",
      "- this really is how vegas fine dining used to be  right down to the menus handed to the ladies that have no prices listed  : This is a POSITIVE review.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predicting values from out test set\n",
    "sample_review = X_test\n",
    "for i in sample_review:\n",
    "    if predict_sentiment(i):\n",
    "        print('-',i,': This is a POSITIVE review.')\n",
    "    else:\n",
    "        print('-',i,': This is a NEGATIVE review!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "658fddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model1,open('Model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837084d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b097ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- very bad : This is a NEGATIVE review!\n",
      "- horrible taste : This is a NEGATIVE review!\n",
      "- bad place : This is a NEGATIVE review!\n"
     ]
    }
   ],
   "source": [
    "# Loading model to compare the results\n",
    "model = pickle.load(open('Model.pkl','rb'))\n",
    "\n",
    "\n",
    "import re   # Regular Expression package\n",
    "\n",
    "#lets define a function for prediction\n",
    "def predict_sentiment(sample_review):\n",
    "    sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ', string = sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    temp = Cvect.transform([sample_review]).toarray()\n",
    "    return model.predict(temp)\n",
    "\n",
    "\n",
    "sample_review = ['very bad','horrible taste','bad place']\n",
    "for i in sample_review:\n",
    "    if predict_sentiment(i):\n",
    "        print('-',i,': This is a POSITIVE review.')\n",
    "    else:\n",
    "        print('-',i,': This is a NEGATIVE review!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a97eb4f1e578222c47ca2a29a7a76bd1da380a24fe52dc15978b44c988031bff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
